{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eccb63e9",
   "metadata": {},
   "source": [
    "# Environment Setup with dotenv\n",
    "\n",
    "We'll use `python-dotenv` to manage our environment variables securely. Create a `.env` file in your project root with:\n",
    "\n",
    "```\n",
    "GOOGLE_API_KEY=your_google_api_key_here\n",
    "```\n",
    "\n",
    "This keeps sensitive information out of your code and makes it easier to manage different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d1adc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .env file at: /media/rgukt/data/RAG/.env\n",
      "✅ GOOGLE_API_KEY loaded successfully\n",
      "API Key (masked): AIza...5wK8\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# Try to find and load the .env file\n",
    "env_path = find_dotenv()\n",
    "if env_path:\n",
    "    print(f\"Found .env file at: {env_path}\")\n",
    "    load_dotenv(env_path, override=True)  # override=True to ensure variables are updated\n",
    "else:\n",
    "    print(\"❌ No .env file found\")\n",
    "    \n",
    "# Verify environment variables are loaded\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if google_api_key:\n",
    "    print(\"✅ GOOGLE_API_KEY loaded successfully\")\n",
    "    # Mask the key for security\n",
    "    masked_key = google_api_key[:4] + \"...\" + google_api_key[-4:]\n",
    "    print(f\"API Key (masked): {masked_key}\")\n",
    "else:\n",
    "    print(\"❌ GOOGLE_API_KEY not found in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -q langchain chromadb langchain-google-genai google-generativeai python-dotenv langchain-community wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6aec9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/rgukt/data/RAG/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769a6bc",
   "metadata": {},
   "source": [
    "## Wikipedia Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d05315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0263e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = WikipediaRetriever(top_k_results=2, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48886ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"The history of the how the sequence to sequence models are improved\"\n",
    "\n",
    "docs = retriver.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a12e16c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'The Simpsons opening sequence', 'summary': 'The Simpsons opening sequence is the title sequence of the American animated television series The Simpsons. It is accompanied by \"The Simpsons Theme\". The first episode to use this introduction was the series\\' second episode \"Bart the Genius\".\\nEach episode has the same basic sequence of events: the camera zooms through cumulus clouds, through the show\\'s title towards the town of Springfield. The camera then follows the members of the Simpson family on their way home. Upon entering their house, the Simpsons settle down on their couch to watch television. One of the most distinctive aspects of the opening is that three of its elements change from episode to episode: Bart writes different phrases on the school chalkboard, Lisa plays different solos on her saxophone (or occasionally a different instrument), and different visual gags accompany the family as they enter their living room to sit on the couch.\\nThe standard opening has had two major revisions. The first was at the start of the second season when the entire sequence was reanimated to improve the quality and certain shots were changed generally to add characters who had been established in the first season. The second was a brand-new opening sequence produced in high-definition for the show\\'s transition to that format beginning with \"Take My Life, Please\" in season 20. The new opening generally followed the sequence of the original opening with improved graphics, even more characters, and new jokes.', 'source': 'https://en.wikipedia.org/wiki/The_Simpsons_opening_sequence'}, page_content='The Simpsons opening sequence is the title sequence of the American animated television series The Simpsons. It is accompanied by \"The Simpsons Theme\". The first episode to use this introduction was the series\\' second episode \"Bart the Genius\".\\nEach episode has the same basic sequence of events: the camera zooms through cumulus clouds, through the show\\'s title towards the town of Springfield. The camera then follows the members of the Simpson family on their way home. Upon entering their house, the Simpsons settle down on their couch to watch television. One of the most distinctive aspects of the opening is that three of its elements change from episode to episode: Bart writes different phrases on the school chalkboard, Lisa plays different solos on her saxophone (or occasionally a different instrument), and different visual gags accompany the family as they enter their living room to sit on the couch.\\nThe standard opening has had two major revisions. The first was at the start of the second season when the entire sequence was reanimated to improve the quality and certain shots were changed generally to add characters who had been established in the first season. The second was a brand-new opening sequence produced in high-definition for the show\\'s transition to that format beginning with \"Take My Life, Please\" in season 20. The new opening generally followed the sequence of the original opening with improved graphics, even more characters, and new jokes.\\n\\n\\n== Sequence ==\\n\\n\\n=== Season 1 ===\\nThis sequence opens with the show\\'s title in yellow approaching the camera through misty cumulus clouds in a dark blue sky. The shot cuts through the counter in the letter \"P\" to an establishing shot of the town of Springfield.\\nThe camera zooms in through the town, toward a lavender Springfield Elementary and then through a window to a lavender classroom, where Bart is writing lines on the chalkboard as a punishment, and three drawings are seen on the wall. When the school bell rings, Bart leaves in a hurry and skateboards out of the school doors.\\nThe shot cuts to Homer working at the Springfield Nuclear Power Plant wearing a safety mask while handling a glowing green rod of uranium with a pair of silver tongs. An unknown co-worker in the background eats a sandwich with another pair of tongs. The end-of-shift whistle blows, and Homer immediately takes off his mask and drops his tongs to leave work. As he does so, the uranium rod bounces into the air and falls down the back of his radiation suit.\\nThe next shot shows Marge and Maggie checking out at a supermarket. Maggie, who is sitting on the conveyor belt, is inadvertently scanned along with the groceries as Marge reads a magazine. Maggie is rung up at a price of US$847.63 (representing the monthly cost of raising a child at the time) and bagged. Marge frantically looks around for Maggie as the bag is dropped into her shopping cart which startles her and makes her turn around, then breathes a sigh of relief when Maggie pops up from the bag.\\nLisa is shown next at band practice. The opening theme coordinates with this shot, and is orchestrated as if it were played by the school band. Mr. Largo stops the rest of the band to order Lisa out of the rehearsal for her unorthodox playing of her saxophone, which is light blue in this sequence, but gold in the episode. She continues to improvise on her way out of the room.\\nShots of the family on their way home to 742 Evergreen Terrace are then shown. As Homer drives through Springfield, he fumbles behind his neck, pulls the uranium rod out of his shirt collar, and throws it out the car window. As it bounces off the curb near Moe\\'s Tavern, Bart skateboards past, noticing a bank of televisions in a store window he passes showing Krusty the Clown; he then passes a bus stop and unwittingly steals its sign. The five unknown characters waiting at the stop then chase after a bus that fails to stop for them.\\nAs soon as Bart crosses the road, a car drives past'),\n",
       " Document(metadata={'title': 'Large language model', 'summary': \"A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation. The largest and most capable LLMs are generative pre-trained transformers (GPTs) and provide the core capabilities of chatbots such as ChatGPT, Gemini and Claude. LLMs can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.\\nThey consist of billions to trillions of parameters and operate as general-purpose sequence models, generating, summarizing, translating, and reasoning over text. LLMs represent a significant new technology in their ability to generalize across tasks with minimal task-specific supervision, enabling capabilities like conversational agents, code generation, knowledge retrieval, and automated reasoning that previously required bespoke systems.\\nLLMs evolved from earlier statistical and recurrent neural network approaches to language modeling. The transformer architecture, introduced in 2017, replaced recurrence with self-attention, allowing efficient parallelization, longer context handling, and scalable training on unprecedented data volumes. This innovation enabled models like GPT, BERT, and their successors, which demonstrated emergent behaviors at scale such as few-shot learning and compositional reasoning.\\nReinforcement learning, particularly policy gradient algorithms, has been adapted to fine-tune LLMs for desired behaviors beyond raw next-token prediction. Reinforcement learning from human feedback (RLHF) applies these methods to optimize a policy, the LLM's output distribution, against reward signals derived from human or automated preference judgments. This has been critical for aligning model outputs with user expectations, improving factuality, reducing harmful responses, and enhancing task performance.\\nMechanistic interpretability seeks to precisely identify and understand how individual neurons or circuits within LLMs produce specific behaviors or outputs. By reverse-engineering model components at a granular level, researchers aim to detect and mitigate safety concerns such as emergent harmful behaviors, biases, deception, or unintended goal pursuit before deployment.\\nBenchmark evaluations for LLMs have evolved from narrow linguistic assessments toward comprehensive, multi-task evaluations measuring reasoning, factual accuracy, alignment, and safety. Hill climbing, iteratively optimizing models against benchmarks, has emerged as a dominant strategy, producing rapid incremental performance gains but raising concerns of overfitting to benchmarks rather than achieving genuine generalization or robust capability improvements.\\nThe convergence of large-scale supervised pretraining, transformer architectures, and reinforcement learning–based fine-tuning marks the current frontier of LLM technology. This combined trajectory underpins the rapid progress in AI systems that deliver tangible benefits to end users: higher accuracy, greater adaptability, improved safety, and broader applicability across scientific, commercial, and creative domains.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Large_language_model'}, page_content='A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation. The largest and most capable LLMs are generative pre-trained transformers (GPTs) and provide the core capabilities of chatbots such as ChatGPT, Gemini and Claude. LLMs can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.\\nThey consist of billions to trillions of parameters and operate as general-purpose sequence models, generating, summarizing, translating, and reasoning over text. LLMs represent a significant new technology in their ability to generalize across tasks with minimal task-specific supervision, enabling capabilities like conversational agents, code generation, knowledge retrieval, and automated reasoning that previously required bespoke systems.\\nLLMs evolved from earlier statistical and recurrent neural network approaches to language modeling. The transformer architecture, introduced in 2017, replaced recurrence with self-attention, allowing efficient parallelization, longer context handling, and scalable training on unprecedented data volumes. This innovation enabled models like GPT, BERT, and their successors, which demonstrated emergent behaviors at scale such as few-shot learning and compositional reasoning.\\nReinforcement learning, particularly policy gradient algorithms, has been adapted to fine-tune LLMs for desired behaviors beyond raw next-token prediction. Reinforcement learning from human feedback (RLHF) applies these methods to optimize a policy, the LLM\\'s output distribution, against reward signals derived from human or automated preference judgments. This has been critical for aligning model outputs with user expectations, improving factuality, reducing harmful responses, and enhancing task performance.\\nMechanistic interpretability seeks to precisely identify and understand how individual neurons or circuits within LLMs produce specific behaviors or outputs. By reverse-engineering model components at a granular level, researchers aim to detect and mitigate safety concerns such as emergent harmful behaviors, biases, deception, or unintended goal pursuit before deployment.\\nBenchmark evaluations for LLMs have evolved from narrow linguistic assessments toward comprehensive, multi-task evaluations measuring reasoning, factual accuracy, alignment, and safety. Hill climbing, iteratively optimizing models against benchmarks, has emerged as a dominant strategy, producing rapid incremental performance gains but raising concerns of overfitting to benchmarks rather than achieving genuine generalization or robust capability improvements.\\nThe convergence of large-scale supervised pretraining, transformer architectures, and reinforcement learning–based fine-tuning marks the current frontier of LLM technology. This combined trajectory underpins the rapid progress in AI systems that deliver tangible benefits to end users: higher accuracy, greater adaptability, improved safety, and broader applicability across scientific, commercial, and creative domains.\\n\\n\\n== History ==\\n\\nBefore the emergence of transformer-based models in 2017, some language models were considered large relative to the computational and data constraints of their time. In the early 1990s, IBM\\'s statistical models pioneered word alignment techniques for machine translation, laying the groundwork for corpus-based language modeling. In 2001, a smoothed n-gram model, such as those employing Kneser–Ney smoothing, trained on 300 million words, achieved state-of-the-art perplexity on benchmark tests. During the 2000s, with the rise of widespread internet access, researchers began compiling massive text datasets from the web (\"web as corpus\") to ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fdfc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your query\n",
    "query = \"the geopolitical history of india and pakistan from the perspective of a chinese\"\n",
    "\n",
    "# Get relevant Wikipedia documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909bcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2 = retriver.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f65afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "page_content='The United States has been providing military aid and economic assistance to Pakistan for various purposes since 1948. In 2017, the U.S. stopped military aid to Pakistan, which was about US$2 billion per year. With U.S. military assistance suspended in 2018 and civilian aid reduced to about $300 million for 2022, Pakistani authorities have turned to other countries for help.\n",
      "\n",
      "\n",
      "== History ==\n",
      "From 1947 to 1958, under civilian leadership, the United States provided Pakistan with modest economic aid and limited military assistance. During this period, Pakistan became a member of the South East Asian Treaty Organization (SEATO) and the Central Treaty Organization (CENTO), after a Mutual Defence Assistance Agreement signed in May 1954, which facilitated increased levels of both economic and military aid from the U.S.\n",
      "In 1958, Ayub Khan led Pakistan's first military coup, becoming Chief Martial Law Administrator (CMLA) and later President until 1969. During his tenure, the U.S. delivered substantial economic and military aid, despite Pakistan's governance by military regime, and amidst events like the Indo-Pakistani war of 1965.\n",
      "Yahya Khan succeeded Ayub in 1969, holding power during the Indo-Pakistani war of 1971 which led to the secession of East Pakistan and the formation of Bangladesh. Under Yahya, the U.S. provided adequate economic but minimal military aid.\n",
      "Civilian governance of Zulfikar Ali Bhutto resumed from 1971 to 1977, during which the U.S. offered modest economic support and withheld military aid as Pakistan finalized its constitution, establishing a parliamentary democracy.\n",
      "Following another military coup in 1977, Muhammad Zia-ul-Haq led the country. In April 1979, President Jimmy Carter halted all aid, excluding food assistance, due to Pakistan's efforts to establish a uranium enrichment facility, following Symington Amendment. Initial U.S. aid was limited, increasing significantly after geopolitical shifts such as the Soviet invasion of Afghanistan in 1979 and the fall of the Shah of Iran. U.S. sanctions imposed in April 1979 due to Pakistan's nuclear activities were lifted by the end of the year in light of these events.\n",
      "Between 1988 and 1999, under civilian and democratic governments, U.S. aid was low, particularly after the Soviet withdrawal from Afghanistan in 1989. The aid was suspended in the 1990s under President George H. W. Bush, who cited concerns over Pakistan's developing nuclear program. Relations between the two countries deteriorated as the U.S. implemented the Pressler Amendment. This amendment led to severe sanctions against Pakistan, exacerbating economic challenges for the country's nascent civilian government. Consequently, all forms of bilateral aid from the U.S. to Pakistan were halted. The once expansive operations of the U.S. Agency for International Development (USAID) in Pakistan, which had employed over 1,000 staff across the country, were dramatically reduced almost overnight. Further complications arose from U.S. sanctions following Pakistan's nuclear tests in 1998, which were conducted in response to similar tests by India.\n",
      "The return of military rule under Pervez Musharraf from 1999 to 2008 initially saw little U.S. economic or military aid. However, following the September 11, 2001 attacks, all U.S. sanctions were removed, and Pakistan, having aligned with the U.S. in the War on Terror, received substantial increases in both economic and military assistance.\n",
      "On June 16, 2009, the U.S. Senate Foreign Relations Committee passed the Enhanced Partnership with Pakistan Act of 2009, commonly referred to as the Kerry-Lugar Bill. The bipartisan act authorized an annual provision of $1.5 billion in U.S. aid to Pakistan, aimed at fostering enhanced bilateral relations.\n",
      "In 2011, the Obama administration suspended more than one-third of all military assistance, totaling approximately $800 million due to Osama bin Laden-related controversy. This reduction encompassed funds designated for military h' metadata={'title': 'United States aid to Pakistan', 'summary': 'The United States has been providing military aid and economic assistance to Pakistan for various purposes since 1948. In 2017, the U.S. stopped military aid to Pakistan, which was about US$2 billion per year. With U.S. military assistance suspended in 2018 and civilian aid reduced to about $300 million for 2022, Pakistani authorities have turned to other countries for help.', 'source': 'https://en.wikipedia.org/wiki/United_States_aid_to_Pakistan'}\n"
     ]
    }
   ],
   "source": [
    "print(type(docs2))\n",
    "print(docs2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50d8e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f59aaeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Content:\n",
      "The Simpsons opening sequence is the title sequence of the American animated television series The Simpsons. It is accompanied by \"The Simpsons Theme\". The first episode to use this introduction was the series' second episode \"Bart the Genius\".\n",
      "Each episode has the same basic sequence of events: the camera zooms through cumulus clouds, through the show's title towards the town of Springfield. The camera then follows the members of the Simpson family on their way home. Upon entering their house, the Simpsons settle down on their couch to watch television. One of the most distinctive aspects of the opening is that three of its elements change from episode to episode: Bart writes different phrases on the school chalkboard, Lisa plays different solos on her saxophone (or occasionally a different instrument), and different visual gags accompany the family as they enter their living room to sit on the couch.\n",
      "The standard opening has had two major revisions. The first was at the start of the second season when the entire sequence was reanimated to improve the quality and certain shots were changed generally to add characters who had been established in the first season. The second was a brand-new opening sequence produced in high-definition for the show's transition to that format beginning with \"Take My Life, Please\" in season 20. The new opening generally followed the sequence of the original opening with improved graphics, even more characters, and new jokes.\n",
      "\n",
      "\n",
      "== Sequence ==\n",
      "\n",
      "\n",
      "=== Season 1 ===\n",
      "This sequence opens with the show's title in yellow approaching the camera through misty cumulus clouds in a dark blue sky. The shot cuts through the counter in the letter \"P\" to an establishing shot of the town of Springfield.\n",
      "The camera zooms in through the town, toward a lavender Springfield Elementary and then through a window to a lavender classroom, where Bart is writing lines on the chalkboard as a punishment, and three drawings are seen on the wall. When the school bell rings, Bart leaves in a hurry and skateboards out of the school doors.\n",
      "The shot cuts to Homer working at the Springfield Nuclear Power Plant wearing a safety mask while handling a glowing green rod of uranium with a pair of silver tongs. An unknown co-worker in the background eats a sandwich with another pair of tongs. The end-of-shift whistle blows, and Homer immediately takes off his mask and drops his tongs to leave work. As he does so, the uranium rod bounces into the air and falls down the back of his radiation suit.\n",
      "The next shot shows Marge and Maggie checking out at a supermarket. Maggie, who is sitting on the conveyor belt, is inadvertently scanned along with the groceries as Marge reads a magazine. Maggie is rung up at a price of US$847.63 (representing the monthly cost of raising a child at the time) and bagged. Marge frantically looks around for Maggie as the bag is dropped into her shopping cart which startles her and makes her turn around, then breathes a sigh of relief when Maggie pops up from the bag.\n",
      "Lisa is shown next at band practice. The opening theme coordinates with this shot, and is orchestrated as if it were played by the school band. Mr. Largo stops the rest of the band to order Lisa out of the rehearsal for her unorthodox playing of her saxophone, which is light blue in this sequence, but gold in the episode. She continues to improvise on her way out of the room.\n",
      "Shots of the family on their way home to 742 Evergreen Terrace are then shown. As Homer drives through Springfield, he fumbles behind his neck, pulls the uranium rod out of his shirt collar, and throws it out the car window. As it bounces off the curb near Moe's Tavern, Bart skateboards past, noticing a bank of televisions in a store window he passes showing Krusty the Clown; he then passes a bus stop and unwittingly steals its sign. The five unknown characters waiting at the stop then chase after a bus that fails to stop for them.\n",
      "As soon as Bart crosses the road, a car drives past...\n",
      "\n",
      "--- Result 2 ---\n",
      "Content:\n",
      "A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation. The largest and most capable LLMs are generative pre-trained transformers (GPTs) and provide the core capabilities of chatbots such as ChatGPT, Gemini and Claude. LLMs can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.\n",
      "They consist of billions to trillions of parameters and operate as general-purpose sequence models, generating, summarizing, translating, and reasoning over text. LLMs represent a significant new technology in their ability to generalize across tasks with minimal task-specific supervision, enabling capabilities like conversational agents, code generation, knowledge retrieval, and automated reasoning that previously required bespoke systems.\n",
      "LLMs evolved from earlier statistical and recurrent neural network approaches to language modeling. The transformer architecture, introduced in 2017, replaced recurrence with self-attention, allowing efficient parallelization, longer context handling, and scalable training on unprecedented data volumes. This innovation enabled models like GPT, BERT, and their successors, which demonstrated emergent behaviors at scale such as few-shot learning and compositional reasoning.\n",
      "Reinforcement learning, particularly policy gradient algorithms, has been adapted to fine-tune LLMs for desired behaviors beyond raw next-token prediction. Reinforcement learning from human feedback (RLHF) applies these methods to optimize a policy, the LLM's output distribution, against reward signals derived from human or automated preference judgments. This has been critical for aligning model outputs with user expectations, improving factuality, reducing harmful responses, and enhancing task performance.\n",
      "Mechanistic interpretability seeks to precisely identify and understand how individual neurons or circuits within LLMs produce specific behaviors or outputs. By reverse-engineering model components at a granular level, researchers aim to detect and mitigate safety concerns such as emergent harmful behaviors, biases, deception, or unintended goal pursuit before deployment.\n",
      "Benchmark evaluations for LLMs have evolved from narrow linguistic assessments toward comprehensive, multi-task evaluations measuring reasoning, factual accuracy, alignment, and safety. Hill climbing, iteratively optimizing models against benchmarks, has emerged as a dominant strategy, producing rapid incremental performance gains but raising concerns of overfitting to benchmarks rather than achieving genuine generalization or robust capability improvements.\n",
      "The convergence of large-scale supervised pretraining, transformer architectures, and reinforcement learning–based fine-tuning marks the current frontier of LLM technology. This combined trajectory underpins the rapid progress in AI systems that deliver tangible benefits to end users: higher accuracy, greater adaptability, improved safety, and broader applicability across scientific, commercial, and creative domains.\n",
      "\n",
      "\n",
      "== History ==\n",
      "\n",
      "Before the emergence of transformer-based models in 2017, some language models were considered large relative to the computational and data constraints of their time. In the early 1990s, IBM's statistical models pioneered word alignment techniques for machine translation, laying the groundwork for corpus-based language modeling. In 2001, a smoothed n-gram model, such as those employing Kneser–Ney smoothing, trained on 300 million words, achieved state-of-the-art perplexity on benchmark tests. During the 2000s, with the rise of widespread internet access, researchers began compiling massive text datasets from the web (\"web as corpus\") to ...\n"
     ]
    }
   ],
   "source": [
    "# Print retrieved content\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(f\"Content:\\n{doc.page_content}...\")  # truncate for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "294ad708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Content:\n",
      "The United States has been providing military aid and economic assistance to Pakistan for various purposes since 1948. In 2017, the U.S. stopped military aid to Pakistan, which was about US$2 billion per year. With U.S. military assistance suspended in 2018 and civilian aid reduced to about $300 million for 2022, Pakistani authorities have turned to other countries for help.\n",
      "\n",
      "\n",
      "== History ==\n",
      "From 1947 to 1958, under civilian leadership, the United States provided Pakistan with modest economic aid and limited military assistance. During this period, Pakistan became a member of the South East Asian Treaty Organization (SEATO) and the Central Treaty Organization (CENTO), after a Mutual Defence Assistance Agreement signed in May 1954, which facilitated increased levels of both economic and military aid from the U.S.\n",
      "In 1958, Ayub Khan led Pakistan's first military coup, becoming Chief Martial Law Administrator (CMLA) and later President until 1969. During his tenure, the U.S. delivered substantial economic and military aid, despite Pakistan's governance by military regime, and amidst events like the Indo-Pakistani war of 1965.\n",
      "Yahya Khan succeeded Ayub in 1969, holding power during the Indo-Pakistani war of 1971 which led to the secession of East Pakistan and the formation of Bangladesh. Under Yahya, the U.S. provided adequate economic but minimal military aid.\n",
      "Civilian governance of Zulfikar Ali Bhutto resumed from 1971 to 1977, during which the U.S. offered modest economic support and withheld military aid as Pakistan finalized its constitution, establishing a parliamentary democracy.\n",
      "Following another military coup in 1977, Muhammad Zia-ul-Haq led the country. In April 1979, President Jimmy Carter halted all aid, excluding food assistance, due to Pakistan's efforts to establish a uranium enrichment facility, following Symington Amendment. Initial U.S. aid was limited, increasing significantly after geopolitical shifts such as the Soviet invasion of Afghanistan in 1979 and the fall of the Shah of Iran. U.S. sanctions imposed in April 1979 due to Pakistan's nuclear activities were lifted by the end of the year in light of these events.\n",
      "Between 1988 and 1999, under civilian and democratic governments, U.S. aid was low, particularly after the Soviet withdrawal from Afghanistan in 1989. The aid was suspended in the 1990s under President George H. W. Bush, who cited concerns over Pakistan's developing nuclear program. Relations between the two countries deteriorated as the U.S. implemented the Pressler Amendment. This amendment led to severe sanctions against Pakistan, exacerbating economic challenges for the country's nascent civilian government. Consequently, all forms of bilateral aid from the U.S. to Pakistan were halted. The once expansive operations of the U.S. Agency for International Development (USAID) in Pakistan, which had employed over 1,000 staff across the country, were dramatically reduced almost overnight. Further complications arose from U.S. sanctions following Pakistan's nuclear tests in 1998, which were conducted in response to similar tests by India.\n",
      "The return of military rule under Pervez Musharraf from 1999 to 2008 initially saw little U.S. economic or military aid. However, following the September 11, 2001 attacks, all U.S. sanctions were removed, and Pakistan, having aligned with the U.S. in the War on Terror, received substantial increases in both economic and military assistance.\n",
      "On June 16, 2009, the U.S. Senate Foreign Relations Committee passed the Enhanced Partnership with Pakistan Act of 2009, commonly referred to as the Kerry-Lugar Bill. The bipartisan act authorized an annual provision of $1.5 billion in U.S. aid to Pakistan, aimed at fostering enhanced bilateral relations.\n",
      "In 2011, the Obama administration suspended more than one-third of all military assistance, totaling approximately $800 million due to Osama bin Laden-related controversy. This reduction encompassed funds designated for military h...\n",
      "\n",
      "--- Result 2 ---\n",
      "Content:\n",
      "Pakistan and the United States established relations on 15 August 1947, a day after the independence of Pakistan, when the United States became one of the first nations to recognise the country.\n",
      "The relationship between the two nations has been described as a \"roller coaster\" characterised by close coordination and lows marked by deep bilateral estrangement. Despite its troubled history, the Pakistani military once occupied an important place in American geopolitical strategy, and has been a major non-NATO ally since 2002. After Pakistan's participation in the Afghan peace process and the Taliban takeover in Afghanistan in 2021, a sizeable number of US policy makers are revisiting the United States' relations with Pakistan. At the same time, the strategic convergence of the United States and India has also brought greater pressure on Pakistani diplomacy.\n",
      "\n",
      "\n",
      "== Background ==\n",
      "\n",
      "During the Cold War (1945–1991), Pakistan allied itself with the Western Bloc led by the United States against the Eastern Bloc led by the Soviet Union, with the former advocating the economic system of capitalism while the latter advocated socialism. Following the 1958 Pakistani military coup, president Muhammad Ayub Khan established a strong military alliance with the United States. During the Bangladesh Liberation War and the Indo-Pakistani War of 1971, the United States aided Pakistan against the Provisional Government of Bangladesh and India. After the Pakistani defeat, Pakistan's leader Zulfikar Ali Bhutto, an anti-American, improved relations with the Soviets. In 1977, Bhutto was overthrown in a military coup led by Muhammad Zia-ul-Haq. Following the Soviet invasion of Afghanistan in 1979, Pakistan and the United States cooperated in the funding and financing of the anti-communist Afghan Mujahideen and then in the ensuing First Afghan Civil War. The United States has imposed sanctions on Pakistan on various occasions to force Pakistan to comply with its strategic interests since 1965, with Pakistan's willingness to participate with the United States in the wars in Somalia and Bosnia, relations improved. However, the United States again suspended aid and imposed sanctions along with India in 1998, only to be lifted once again with the United States engagement in Afghanistan in 2001. Factors involving in the contingency operations, distrust, and different priorities of both nations in the Afghan War led to serious criticism as both sides began to criticize each other's strategy to achieve common goals in the War on Terror. The United States continues to blame Pakistan's military for supporting non-state actors, including the Taliban. Furthermore, drone strikes by both nations, a friendly fire incident at Salala, and an incident involving the arrest of a spy in Lahore further complicated relations for the worse.\n",
      "\n",
      "\n",
      "=== Third-party factors in Pakistan–U.S. relations ===\n",
      "\n",
      "The U.S.'s troubled relationship with Pakistan continues to be eroded by crisis after crisis. It has been alleged that the ISI of Pakistan pays journalists to write articles hostile to the United States in the early 2010s. Despite this, both Pakistan and the United States continue to seek a productive relationship to defeat terrorist organizations in the War on Terror. But in recent years, \"Islamabad has arguably lost some of its strategic significance in the West following the US/NATO withdrawal from Afghanistan\". Pakistan once provided NATO with a supply route to Afghanistan, a link that dominated bilateral relations during the war. However, with the end of the war and the withdrawal of US troops from the region in the early 2020s, Pakistan's influence on the US disappeared and the US no longer needed it to engage with Afghanistan.\n",
      "Pakistan's decades-long rivalry and conflict with the U.S. strategic partner India in the context of Kashmir and all-weather strategic cooperation with China in the context of great power competition between the United States and China poses difficulties for ...\n"
     ]
    }
   ],
   "source": [
    "# Print retrieved content\n",
    "for i, doc in enumerate(docs2):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(f\"Content:\\n{doc.page_content}...\")  # truncate for display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960e7cc",
   "metadata": {},
   "source": [
    "## Vector store retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b155501",
   "metadata": {},
   "source": [
    "# Vector Store Retriever with Chroma\n",
    "\n",
    "## Prerequisites:\n",
    "1. Properly initialized OpenAI API key\n",
    "2. Installed dependencies (chromadb, openai)\n",
    "3. Valid documents with content\n",
    "4. Working embedding model\n",
    "\n",
    "## Common Issues:\n",
    "1. OpenAI API key not set or invalid\n",
    "2. Embedding model initialization failed\n",
    "3. Documents not in correct format\n",
    "4. Chroma persistence directory issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd649c0e",
   "metadata": {},
   "source": [
    "# Using Google's Gemini Embeddings\n",
    "\n",
    "## Advantages of Gemini Embeddings:\n",
    "1. High-quality text representations\n",
    "2. Optimized for different tasks (retrieval, classification, etc.)\n",
    "3. Cost-effective compared to other options\n",
    "4. Good performance on multilingual content\n",
    "\n",
    "## Model Details:\n",
    "- Model: `gemini-embedding-001`\n",
    "- Task Type: `retrieval_document`\n",
    "- Output: High-dimensional vectors (suitable for semantic search)\n",
    "- Integration: Seamless with LangChain and ChromaDB\n",
    "\n",
    "## Requirements:\n",
    "1. Google API key in environment variables\n",
    "2. `langchain-google-genai` package installed\n",
    "3. `google-generativeai` Python package\n",
    "4. Proper task type configuration for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cab71979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_22361/2474575869.py\", line 1, in <module>\n",
      "    from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/langchain_google_genai/__init__.py\", line 59, in <module>\n",
      "    from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/langchain_google_genai/chat_models.py\", line 58, in <module>\n",
      "    from langchain_core.language_models import LanguageModelInput\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/langchain_core/language_models/__init__.py\", line 112, in __getattr__\n",
      "    result = import_attr(attr_name, module_name, __spec__.parent)\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/langchain_core/_import_utils.py\", line 36, in import_attr\n",
      "    module = import_module(f\".{module_name}\", package=package)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/langchain_core/language_models/base.py\", line 44, in <module>\n",
      "    from transformers import GPT2TokenizerFast  # type: ignore[import-not-found]\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/transformers/__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n",
      "    from .auto_docstring import (\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/transformers/utils/auto_docstring.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/transformers/utils/generic.py\", line 51, in <module>\n",
      "    import torch  # noqa: F401\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/media/rgukt/data/RAG/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b18cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Your source documents\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
    "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
    "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
    "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218f4764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760084985.663186   22361 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "656bd6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create Chroma vector store in memory\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"my_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65bca470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Convert vectorstore into a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c52a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Chroma used for?\"\n",
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc365a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Chroma is a vector database optimized for LLM-based search.\n",
      "\n",
      "--- Result 2 ---\n",
      "LangChain helps developers build LLM applications easily.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e8e596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66074250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Chroma is a vector database optimized for LLM-based search.\n",
      "\n",
      "--- Result 2 ---\n",
      "LangChain helps developers build LLM applications easily.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ccc2d",
   "metadata": {},
   "source": [
    "## MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47ecffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain makes it easy to work with LLMs.\"),\n",
    "    Document(page_content=\"LangChain is used to build LLM based applications.\"),\n",
    "    Document(page_content=\"Chroma is used to store and search document embeddings.\"),\n",
    "    Document(page_content=\"Embeddings are vector representations of text.\"),\n",
    "    Document(page_content=\"MMR helps you get diverse results when doing similarity search.\"),\n",
    "    Document(page_content=\"LangChain supports Chroma, FAISS, Pinecone, and more.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a401f1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760084988.563849   22361 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embedding_model =GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "# Step 2: Create the FAISS vector store from documents\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0bc21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable MMR in the retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",                   # <-- This enables MMR\n",
    "    search_kwargs={\"k\": 3, \"lambda_mult\": 1}  # k = top results, lambda_mult = relevance-diversity balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2277b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is langchain?\"\n",
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "032e66f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='d9bc7c92-6b30-40a2-8227-0b5ac95569c1', metadata={}, page_content='LangChain is used to build LLM based applications.'),\n",
       " Document(id='f8538277-5d61-4849-a2e4-3127df1bd697', metadata={}, page_content='LangChain makes it easy to work with LLMs.'),\n",
       " Document(id='00f62938-7097-4a95-b280-cf7ccbbe5faf', metadata={}, page_content='LangChain supports Chroma, FAISS, Pinecone, and more.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(results))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9df6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='LangChain is used to build LLM based applications.'\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "141ccf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is used to build LLM based applications.\n",
      "LangChain makes it easy to work with LLMs.\n",
      "LangChain supports Chroma, FAISS, Pinecone, and more.\n"
     ]
    }
   ],
   "source": [
    "for doc in results:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60465571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "LangChain is used to build LLM based applications.\n",
      "\n",
      "--- Result 2 ---\n",
      "LangChain makes it easy to work with LLMs.\n",
      "\n",
      "--- Result 3 ---\n",
      "LangChain supports Chroma, FAISS, Pinecone, and more.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c86e56",
   "metadata": {},
   "source": [
    "## Multiquery Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea796cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f62629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant health & wellness documents\n",
    "all_docs = [\n",
    "    Document(page_content=\"Regular walking boosts heart health and can reduce symptoms of depression.\", metadata={\"source\": \"H1\"}),\n",
    "    Document(page_content=\"Consuming leafy greens and fruits helps detox the body and improve longevity.\", metadata={\"source\": \"H2\"}),\n",
    "    Document(page_content=\"Deep sleep is crucial for cellular repair and emotional regulation.\", metadata={\"source\": \"H3\"}),\n",
    "    Document(page_content=\"Mindfulness and controlled breathing lower cortisol and improve mental clarity.\", metadata={\"source\": \"H4\"}),\n",
    "    Document(page_content=\"Drinking sufficient water throughout the day helps maintain metabolism and energy.\", metadata={\"source\": \"H5\"}),\n",
    "    Document(page_content=\"The solar energy system in modern homes helps balance electricity demand.\", metadata={\"source\": \"I1\"}),\n",
    "    Document(page_content=\"Python balances readability with power, making it a popular system design language.\", metadata={\"source\": \"I2\"}),\n",
    "    Document(page_content=\"Photosynthesis enables plants to produce energy by converting sunlight.\", metadata={\"source\": \"I3\"}),\n",
    "    Document(page_content=\"The 2022 FIFA World Cup was held in Qatar and drew global energy and excitement.\", metadata={\"source\": \"I4\"}),\n",
    "    Document(page_content=\"Black holes bend spacetime and store immense gravitational energy.\", metadata={\"source\": \"I5\"}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37ec6d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760086112.074948   22361 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fc7a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore= FAISS.from_documents(\n",
    "    documents=all_docs,\n",
    "    embedding= embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3bb3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retrievers\n",
    "similarity_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec455b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760086357.294579   22361 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    llm= ChatGoogleGenerativeAI(model= 'gemini-2.5-flash')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cb5089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "\n",
    "query = \"How to improve energy levels and maintain balance?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ffd6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve results\n",
    "similarity_results = similarity_retriever.invoke(query)\n",
    "multiquery_results= multiquery_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f563e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Drinking sufficient water throughout the day helps maintain metabolism and energy.\n",
      "\n",
      "--- Result 2 ---\n",
      "The solar energy system in modern homes helps balance electricity demand.\n",
      "\n",
      "--- Result 3 ---\n",
      "Mindfulness and controlled breathing lower cortisol and improve mental clarity.\n",
      "\n",
      "--- Result 4 ---\n",
      "Consuming leafy greens and fruits helps detox the body and improve longevity.\n",
      "\n",
      "--- Result 5 ---\n",
      "Regular walking boosts heart health and can reduce symptoms of depression.\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "--- Result 1 ---\n",
      "Drinking sufficient water throughout the day helps maintain metabolism and energy.\n",
      "\n",
      "--- Result 2 ---\n",
      "Mindfulness and controlled breathing lower cortisol and improve mental clarity.\n",
      "\n",
      "--- Result 3 ---\n",
      "Consuming leafy greens and fruits helps detox the body and improve longevity.\n",
      "\n",
      "--- Result 4 ---\n",
      "Regular walking boosts heart health and can reduce symptoms of depression.\n",
      "\n",
      "--- Result 5 ---\n",
      "The solar energy system in modern homes helps balance electricity demand.\n",
      "\n",
      "--- Result 6 ---\n",
      "Deep sleep is crucial for cellular repair and emotional regulation.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(similarity_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)\n",
    "\n",
    "print(\"*\"*150)\n",
    "\n",
    "for i, doc in enumerate(multiquery_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731e12d",
   "metadata": {},
   "source": [
    "## ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be7478fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import  GoogleGenerativeAIEmbeddings,ChatGoogleGenerativeAI\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9544332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the document objects from the previous data\n",
    "docs = [\n",
    "    Document(page_content=(\n",
    "        \"\"\"The Grand Canyon is one of the most visited natural wonders in the world.\n",
    "        Photosynthesis is the process by which green plants convert sunlight into energy.\n",
    "        Millions of tourists travel to see it every year. The rocks date back millions of years.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc1\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"In medieval Europe, castles were built primarily for defense.\n",
    "        The chlorophyll in plant cells captures sunlight during photosynthesis.\n",
    "        Knights wore armor made of metal. Siege weapons were often used to breach castle walls.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc2\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"Basketball was invented by Dr. James Naismith in the late 19th century.\n",
    "        It was originally played with a soccer ball and peach baskets. NBA is now a global league.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc3\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"The history of cinema began in the late 1800s. Silent films were the earliest form.\n",
    "        Thomas Edison was among the pioneers. Photosynthesis does not occur in animal cells.\n",
    "        Modern filmmaking involves complex CGI and sound design.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc4\"})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd094cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760086765.825022   22361 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "132f2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS vector store from the documents\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "947f172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1136d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760086790.157760   22361 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model= 'gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b502f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1cf84420",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    base_compressor=compressor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fbbf2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the retriever\n",
    "query = \"What is photosynthesis?\"\n",
    "compressed_results = compression_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b100baf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Photosynthesis is the process by which green plants convert sunlight into energy.\n",
      "\n",
      "--- Result 2 ---\n",
      "The chlorophyll in plant cells captures sunlight during photosynthesis.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(compressed_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
